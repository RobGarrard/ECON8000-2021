\documentclass[12pt]{article}

\usepackage{amsmath, amsfonts, amsthm, amssymb}
\usepackage[left = 1in, right = 1in]{geometry}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{multicol}
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage[colorlinks, allcolors=blue]{hyperref}

% Include Solutions
\newif\ifsln
\slnfalse
\slntrue

% No Indent
\setlength\parindent{0pt}


% Common Sets
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\epsilon}{\varepsilon}

\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}

\renewcommand{\iff}{\Leftrightarrow}
\newcommand{\halmos}{\hfill$\blacksquare$}

\newenvironment{amatrix}[1]{%
  \left(\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right)
}

\begin{document}
\pagestyle{fancyplain}


\chead{\textbf{Tutorial 4 \ifsln Solutions \fi}}
\lhead{\textbf{ECON8000}}
\rhead{\textbf{Semester 1, 2021}}

\begin{center}
Solutions due by 10.30am Friday 5\textsuperscript{th} March.
\end{center}

\begin{enumerate}[1.]
\setlength\itemsep{5mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Show that $\E[Y] = \E[ \E[Y \ | \ X ] ]$.

\ifsln
\textit{Solution:}\\

\begin{align*}
\E[ \E[Y\ | \ X]] & = \E\left[ \sum_{y} y \P(Y \ | \ X) \right]\\
&= \sum_{x} \left[  \sum_{y} y \P(Y \ | \ X)\right] \P(X) \\
&= \sum_{x} \left[  \sum_{y} y \P(Y, X)\right] \\
&= \sum_{y} y\left[  \sum_{x}  \P(Y, X)\right] \\
&= \sum_{y} y\P(Y) \\
&= \E[Y]
\end{align*}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Suppose $\sqrt{n} (\mathbf{x} -\mathbf{\mu}) \overset{d}{\to} N(0, \Sigma)$, where $\mathbf{x}$ is a p-vector and $\Sigma$ a $p\times p$ covariance matrix. Show that $n (\mathbf{x} -\mathbf{\mu})^{\prime} \Sigma^{-1} (\mathbf{x} -\mathbf{\mu}) \overset{d}{\to} \chi^{2}(p)$.

\ifsln
\textit{Solution:}\\
Must assume positive definiteness. By Cholesky decomposition, $\Sigma^{-1} = C^{\prime}C$. The quadratic form becomes $v^{\prime} v$ where $v = C \sqrt{n}(\bar{X} - \mu) \sim N(0, C \Sigma C^{\prime})$. The variance term reduces to $C\Sigma C^{\prime} = C (C^{\prime} C)^{-1} C^{\prime} = C (C^{-1} C^{\prime^{-1}}) C^{\prime} = (C C^{-1}) (C^{\prime^{-1}} C^{\prime}) = I$. Therefore $v^{\prime}v \sim \chi^{2}(p)$.
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\item Suppose $\sqrt{n}(\hat{\theta} - \theta) \overset{d}{\to} N(0, \sigma^{2})$. Let $g(x)$ be a differentiable function.

\begin{enumerate}[a)]
	\item  Show that if $g^{\prime}(\theta) \not = 0$, then $\sqrt{n}(g(\hat{\theta} - g(\theta)) \overset{d}{\to} N(0, g^{\prime}(\theta)^{2} \sigma^{2})$.
	\item What's the asymptotic distribution of $\bar{X}^{2}$?
\end{enumerate}

\ifsln
\textit{Solution:}\\
a) By the intermediate value theorem, there exists a $c \in [\theta, \hat{\theta}]$ such that 
\[\sqrt{n}(g(\hat{\theta}) - (\theta)) = g^{\prime}(c) \sqrt{n}(\hat{\theta} - \theta)\]

Since $\hat{\theta} \overset{p}{\to} \theta$ and $\theta \leq c \leq \hat{\theta}$, the squeeze theorem tells us that $c \overset{p}{\to} \theta$. Since $\sqrt{n}(\hat{\theta} - \theta)$ is asymtotically normal, Slutsky's theorem tells us that 
\[\sqrt{n}(g(\hat{\theta}) - g(\theta)) \overset{d}{\to} N(0, g^{\prime}(\theta)^{2} \sigma^{2})\]

In order to not have the distribution collapse, we must have $g^{\prime}(\theta) \not = 0$.\bigskip

b) If $\mu = \E[X] \not =0$, set $g(x) = x^{2}$. $g^{\prime}(\mu) = 2\mu$. Appealing to the central limit theorem for asymptotic normality and applying the above theorem gives $\sqrt{n}(\bar{X}^{2} - \mu^{2}) \overset{d}{\to} N(0, 4\mu^{2}\sigma^{2})$.\medskip

If $\mu = 0$, then $\sqrt{n}\bar{X} \overset{d}{\to} N(0, \sigma^{2})$, so $\frac{\sqrt{n}\bar{X}}{\sigma} \overset{d}{\to} N(0, 1)$. Therefore $\left(\frac{\sqrt{n}\bar{X}}{\sigma}\right)^{2} = \frac{n\bar{X}^{2}}{\sigma^{2}} \overset{d}{\to} \chi^{2}(1)$, so $n\bar{X}^{2} \overset{d}{\to} \sigma^{2}\chi^{2}(1)$.
\fi 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Let $X \sim N(\mu, \sigma^{2})$. Show that $\P(|X - \mu| > k \sigma) \leq 2e^{-k^{2}/2}$.\smallskip

[Hint: Markov's inequality + MGF]


\ifsln
\textit{Solution:}\\
Markov's inequality gives tells us that $\P(X > k) \leq \frac{\E[X]}{k}$, if $X$ is a non-negative rv. Let $Z$ be a standard normal deviate, then 
\[\P(Z > k) = \P(e^{tZ} > e^{tk}) \leq \frac{\E[e^{tZ}]}{e^{tk}} = e^{-tk} e^{t^{2}/2} = e^{t^{2}/2 - tk}\]

Since this holds for all $t$, we can choose a particular $t$ to minimize the RHS. Note that it is minimized when $t = k$ (take derivative, set to zero, check second order conditions). So $\P(Z > k) \leq e^{-k^{2}/2}$. Note that $\P(|Z| > k) = \P(Z > k) + \P(Z < -k)$. Since $Z$ is symmetric, these probabilitities are the same, so 

\[\P(|X - \mu| > \sigma k) = \P(|Z| > k) \leq 2e^{-k^{2}/2}\]
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\item The clinical trial research for the Pfizer vaccine was published in the New England Journal of Medicine: \href{http://www.doi.org/10.1056/NEJMoa2034577}{10.1056/NEJMoa2034577}. The trial consists of two populations: the treated (who received the vaccine) and the placebo (who did not). The study measures the number of COVID infections in each population one week after receiving the second dose.\smallskip

Let $p_{T}$ and $p_{P}$ be the true proportion of people who would became infected with COVID if treated and not treated respectively. Let $n_{T}$ and $n_{P}$ be the number of people in each of the treated and placebo populations respectively, with $\hat{p}_{T}$ and $\hat{p}_{P}$ the sample proportions observed in the study. The incident risk ratio is defined to be $IRR = p_{T} / p_{P}$. The effectiveness of the vaccine is defined to be $1 - IRR$.\smallskip

The Pfizer study reports: 8 COVID infections in the treated group of size $n_{T} = 18,198$; 162 infections in the placebo group of size $n_{P} = 18,325$. 
\begin{enumerate}[a)]
	\item What is the point estimate for vaccine effectiveness: $1 - \widehat{IRR}$?
	\item What asymptotic distribution does $\hat{p} - p$ have for each population?
	\item What asymptotic distribution does $\ln \hat{p}_{T} - \ln \hat{p}_{P}$ have?
	\item Find a 95\% confidence interval for the vaccine effectiveness.
\end{enumerate}

\ifsln
\textit{Solution:}\\
a) $\hat{p}_{T} = \frac{8}{18196}$, $\hat{p}_{P} = \frac{162}{18325}$. $ 1 - \widehat{IRR} = 1 - \frac{\frac{8}{18196}}{\frac{162}{18325}} \approx 95.0\%$\medskip

b) Note that sample proportions are themselves sample means: $\hat{p} = \frac{\# infections}{n} = \frac{1}{n}\sum_{i} I_{i}$ where $I_{i}$ is a Bernoulli random variable for whether person $i$ became infected. This gives $\E[\hat{p}] = p$ and $\mathrm{Var}(\hat{p}) = \frac{p(1-p)}{n}$. Appealing to the central limit theorem gives 

\[ \sqrt{n_{T}} (\hat{p}_{T} - p_{T}) \overset{d}{\to} N(0, p_{T}(1-p_{T})) \qquad \sqrt{n_{P}} (\hat{p}_{P} - p_{P}) \overset{d}{\to} N(0, p_{P}(1-p_{P}))\]
\medskip

c) Let $g(x) = \ln x$, then $g^{\prime}(x) = \frac{1}{x}$. We proved the Delta method above, yielding
\[ \sqrt{n_{T}} (\ln\hat{p}_{T} - \ln p_{T}) \overset{d}{\to} N(0, \frac{1-p_{T}}{p_{T}}) \qquad \sqrt{n_{P}} (\ln \hat{p}_{P} - \ln p_{P}) \overset{d}{\to} N(0, \frac{1-p_{P}}{p_{P}})\]\

Moving $\sqrt{n}$s to the other side and differencing gives

\[(\ln\hat{p}_{T} - \ln p_{T}) - (\ln\hat{p}_{P} - \ln p_{P}) \overset{d}{\to}N(0,  \frac{1-p_{T}}{p_{T}n_{T}} + \frac{1-p_{P}}{p_{P}n_{P}})\]

Or 


\[\ln\hat{p}_{T}  - \ln\hat{p}_{P}  \overset{d}{\to}N(p_{T} - p_{P},  \frac{1-p_{T}}{p_{T}n_{T}} + \frac{1-p_{P}}{p_{P}n_{P}})\]
\medskip

c) Note that $1 - \exp{\ln\hat{p}_{T}  - \ln\hat{p}_{P}} = 1 - \widehat{IRR}$, which is our point estimator for effectiveness. So to make a CI for effectiveness, let's make a CI for the log difference, exponentiate it and subtract that from one. The log difference CI is 

\[\left((\ln\hat{p}_{T}  - \ln\hat{p}_{P}) - z_{1-\alpha/2} \left(\frac{1-p_{T}}{p_{T}n_{T}} + \frac{1-p_{P}}{p_{P}n_{P}}\right), (\ln\hat{p}_{T}  - \ln\hat{p}_{P}) + z_{\alpha/2} \left(\frac{1-p_{T}}{p_{T}n_{T}} + \frac{1-p_{P}}{p_{P}n_{P}}\right) \right)\]

Estimate the standard deviation with our sample proportions: $\sqrt{\frac{1-\hat{p}_{T}}{\hat{p}_{T}n_{T}} + \frac{1-\hat{p}_{P}}{\hat{p}_{P}n_{P}}} \approx 0.362$,. The log difference is approx -3.00, and at the 95\% confidence level, $z_{\alpha/2}=1.96$. This yields a CI of $(-3.71, -2.29)$ for the log difference. Apply our $1 - \exp{\cdot}$ transform to each end point and we get $(.898, 0.975)$. So we can be 95\% confident that vaccine effectiveness is between 89.8\% and 97.5\%. Note that the CI found by the authors is (90.3\%, 97.6\%), they used a slightly different type of confidence interval (not strictly a confidence interval, but a Bayesian credible interval). 
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Suppose an agent needs to know a parameter $\theta$, but cannot observe it directly. Suppose they are given two noisy signals:
\begin{align*}
x = \theta + \epsilon\\
y = \theta + \nu
\end{align*}

where $\theta \sim N(0, \sigma^{2}_{\theta})$, $\epsilon \sim N(0, \sigma^{2}_{\epsilon})$, $\nu \sim N(0, \sigma^{2}_{\nu})$, all pairwise independent. The agent estimates $\theta$ with a linear combination of the signals. What weights should they choose such that their estimator is minimum mean square error?

\ifsln
\textit{Solution:}\\
Look for an estimator of the form $\hat{\theta} = c_{1}x + c_{2}y$. Apply the orthogonality principle. We need:
\begin{align*}
\E[(\hat{\theta} - \theta)\cdot x] = 0\\
\E[(\hat{\theta} - \theta)\cdot y] = 0\\
\end{align*}
This gives 
\begin{align*}
c_{1} (\sigma^{2}_{\theta} + \sigma^{2}_{\epsilon}) + c_{2} \sigma^{2}_{\theta} = \sigma^{2}_{\theta}\\
c_{1} \sigma^{2}_{\theta} + c_{2}(\sigma^{2}_{\theta} + \sigma^{2}_{\nu}) = \sigma^{2}_{\theta}
\end{align*}
Or

\[\begin{pmatrix} \sigma^{2}_{\theta} + \sigma^{2}_{\epsilon} & \sigma^{2}_{\theta} \\ \sigma^{2}_{\theta} & \sigma^{2}_{\theta} + \sigma^{2}_{\nu}\end{pmatrix} \begin{bmatrix}c_{1}\\c_{2}\end{bmatrix} = \begin{bmatrix}\sigma^{2}_{\theta}\\ \sigma^{2}_{\theta} \end{bmatrix}\]
	
\[\begin{bmatrix}c_{1}\\c_{2}\end{bmatrix} = \frac{1}{\sigma^{2}_{\theta}\sigma^{2}_{\nu} + \sigma^{2}_{\theta}\sigma^{2}_{\epsilon} + \sigma^{2}_{\epsilon}\sigma^{2}_{\nu}}\begin{pmatrix} \sigma^{2}_{\theta} + \sigma^{2}_{\nu} & -\sigma^{2}_{\theta} \\ -\sigma^{2}_{\theta} & \sigma^{2}_{\theta} + \sigma^{2}_{\epsilon}\end{pmatrix}  \begin{bmatrix}\sigma^{2}_{\theta}\\ \sigma^{2}_{\theta} \end{bmatrix}\]

Which gives

\[c_{1} = \frac{ \frac{1}{\sigma^{2}_{\epsilon}} } {\frac{1}{\sigma^{2}_{\epsilon}} + \frac{1}{\sigma^{2}_{\nu}} + \frac{1}{\sigma^{2}_{\theta} } }
\qquad 
c_{2} = \frac{ \frac{1}{\sigma^{2}_{\nu}} } {\frac{1}{\sigma^{2}_{\epsilon}} + \frac{1}{\sigma^{2}_{\nu}} + \frac{1}{\sigma^{2}_{\theta} } }
\]

\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Consider the Solow growth model described by
\begin{align}
& k_{t+1} = s k_{t}^{\alpha} + (1-\delta)k_{t}\\
& c_{t} = (1-s) k_{t}^{\alpha}
\end{align}

where $0 \leq \alpha < 1$, $s \in [0, 1]$ is a constant savings rate, and $\delta \in [0, 1]$ is the capital depreciation rate.

\begin{enumerate}[a)]
	\item Solve for the unique steady state levels of capital and consumption.
	\item Find the savings rate that maximizes consumption in the steady state.
	\item Log-linearize the two equations.
	\item Describe the approximate solution as a system of first order difference equations.
\end{enumerate}

\ifsln
\textit{Solution:}\\
a) $\bar{k} = s \bar{k}^{\alpha} + (1-\delta)\bar{k} \implies \delta \bar{k} = s\bar{k}^{\alpha} \implies \bar{k} = (\frac{\delta}{s})^{\frac{1}{\alpha-1}} \implies \bar{k} = (\frac{s}{\delta})^{\frac{1}{1-\alpha}}$. Then $\bar{c} = (1-s)\bar{k}^{\alpha}$.\medskip

b) $\bar(c) = \bar{k}^{\alpha} - s\bar{k}^{\alpha}$. From the capital flow equation we know that in the steady state $s\bar{k}^{\alpha} = \delta \bar{k}$. Let's sub that in to geh $\bar{c} = \bar{k}^{\alpha} - \delta \bar{k}$. Differentiating wrt the savings rate gives
\[\frac{\mathrm{d}\bar{c}}{\mathrm{d} s} = \left[\alpha\bar{k}^{\alpha-1} - \delta\right]\frac{\mathrm{d}\bar{k}}{\mathrm{d} s} = 0\]

Note that  $\frac{\mathrm{d}\bar{k}}{\mathrm{d} s} = 0$ only if $s=0$. So at the optimum we must have $\alpha\bar{k}^{\alpha-1} = \delta$. So $\alpha \left[ \left(\frac{s}{\delta}\right)^{\frac{1}{1-\alpha}}\right]^{\alpha-1} = \delta \implies s = \alpha$.\medskip

c) The capital flow equation becomes: $\bar{k} \hat{k}_{t+1} = \left[\alpha s \bar{k}^{\alpha - 1} + 1 - \delta  \right] \bar{k}\hat{k}_{t}$. The consumption equation becomes $\bar{c}\hat{c}_{t} = \alpha (1-s)\bar{k}^{\alpha-1} \bar{k} \hat{k}_{t}$.\medskip

d) 
\[\begin{pmatrix} 1 & -\alpha(1-s)\bar{k}^{\alpha-1}\bar{k}\\ 0 & 1  \end{pmatrix}\begin{bmatrix}c_{t+1} \\ k_{t+1}  \end{bmatrix}   = \begin{pmatrix} 0 & 0\\ 0 & \alpha s \bar{k}^{\alpha-1} + 1 - \delta   \end{pmatrix} \begin{bmatrix}c_{t} \\ k_{t}  \end{bmatrix}\]
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Log-linearize the following equations assuming a steady state exists:
\begin{enumerate}[a)]
	\item $c_{t} + k_{t+1} = F(k_{t}) + (1-\delta)k_{t}$
	\item $U^{\prime}(c_{t}) = \beta U^{\prime}(c_{t+1})[F^{\prime}(k_{t+1}) + 1 - \delta]$
\end{enumerate}

\ifsln
\textit{Solution:}\\

a) $\bar{c}\hat{c}_{t} + \bar{k}\hat{k}_{t+1} = \left[ F^{\prime}(\bar{k}_{t}) + 1  - \delta \right]\bar{k} \hat{k}_{t}$. Noting that in steady state $1 = \beta [F^{\prime}(\bar{k}) + 1-\delta]$, this reduces to $\bar{c}\hat{c}_{t} + \bar{k}\hat{k}_{t+1} = \beta^{-1}\bar{k} \hat{k}_{t}$ \medskip

b) $U^{\prime\prime}(\bar{c}) \bar{c}\hat{c}_{t} = \beta U^{\prime\prime}(\bar{c})[F^{\prime}(\bar{k}) + 1-\delta]\bar{c}\hat{c}_{t+1} + \beta U^{\prime}(\bar{c})F^{\prime\prime}(\bar{k})\bar{k}\hat{k}_{t+1}$. \\

Divide through by $U^{\prime}(\bar{c})$ and note that in steady state $1 = \beta [F^{\prime}(\bar{k}) + 1-\delta]$.\\

$ \sigma(\bar{c})c_{t} = \sigma(\bar{c})\hat{c}_{t+1} + \beta F^{\prime\prime}(\bar{k})\bar{k}\hat{k}_{t+1}$, where $\sigma(\bar{c}) = \frac{U^{\prime\prime}(\bar{c})\bar{c}}{U^{\prime}(\bar{c})}$, is the Arrow-Pratt measure of risk aversion.

\fi
\end{enumerate}
\end{document}
