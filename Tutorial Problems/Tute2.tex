\documentclass[12pt]{article}

\usepackage{amsmath, amsfonts, amsthm, amssymb}
\usepackage[left = 1in, right = 1in]{geometry}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{multicol}
\usepackage{verbatim}
\usepackage{booktabs}

% Include Solutions
\newif\ifsln
\slnfalse
\slntrue

% No Indent
\setlength\parindent{0pt}


% Common Sets
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\epsilon}{\varepsilon}

\renewcommand{\iff}{\Leftrightarrow}
\newcommand{\halmos}{\hfill$\blacksquare$}

\begin{document}
\pagestyle{fancyplain}


\chead{\textbf{Tutorial 2 \ifsln Solutions \fi}}
\lhead{\textbf{ECON8000}}
\rhead{\textbf{Semester 1, 2021}}

\begin{center}
Solutions due by 10.30am Friday 19\textsuperscript{th} February.
\end{center}

\begin{enumerate}[1.]
\setlength\itemsep{5mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Show that a closed ball is a closed set.

\ifsln

\noindent
\textit{Solution:}\\
Show that the complement of $\bar{B}(x, \epsilon)$ is open. For any $y \in \bar{B}(x, \epsilon)^{c}$, pick $B(y, d(x,y) - \epsilon)$ to be the open ball around $y$. To show that $B(y, d(x,y)-\epsilon) \subset \bar{B}(x, \epsilon)^{c}$, consider any $z \in B(y, d(x,y)-\epsilon)$. By the triangle inequality, $d(x,y) \leq d(x,z) + d(z, y)$. Since $z \in B(y, d(x,y)-\epsilon)$, then $d(z, y) < d(x,y)-\epsilon$. Plugging into the triangle inequality gives $d(x,y) < d(x,z) + d(x,y) - \epsilon$. Rearranging gives $d(x,z)>\epsilon$, hence it is not in $\bar{B}(x, \epsilon)$, and is instead in the complement. \halmos
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Show that if $A\subset X$ is a closed set, and $a_{n} \in A$ is a sequence, then $a_{n} \to a \implies a \in A$.
\ifsln

\noindent
\textit{Solution:}\\
We will prove by contradiction. Suppose that $a \in A^{c}$. Then since the complement of a closed set is open, $\exists \epsilon > 0 $ such that $B(a, \epsilon) \subset A^{c}$. By the definition of convergence, this ball must contain all but finitely many elements of $a_{n}$; however, since it's fully contained in $A^{c}$, it in fact has no elements of $a_{n}$. Contradiction. Therefore $a\in A$.\halmos

\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Show that if a sequence is convergent, then it is Cauchy. 

\ifsln

\noindent
\textit{Solution:}\\
For any $\epsilon > 0$, recall that the defintion of convergence requires that we can find an $N$ such that $\forall m,n > N$, $d(x_{m}, c) < \frac{\epsilon}{2}$ and $d(x_{n}, c) < \frac{\epsilon}{2}$. The triangle inequality gives us that $d(x_{m}, x_{n}) \leq d(x_{m}, c) + d(c, x_{n}) < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$. Thus $\forall \epsilon>0$ $\exists N$ s.t. $\forall m,n > N$ $d(x_{m}, x_{n}) < \epsilon$, which is the definition of a Cauchy sequence.
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Let $\{a_{n}\}_{n=1}^{\infty}$ be a Cauchy sequence. Show that if there is a convergent subsequence, $\{a_{n_{k}}\}_{k=1}^{\infty}$, such that $a_{n_{k}} \to c$ then $a_{n} \to c$. 
\ifsln

\noindent
\textit{Solution:}\\
For $\epsilon > 0$, since $a_{n_{k}} \to c$,  there exists an $N$ large enough such that $d(a_{n_{k}}, c) < \frac{\epsilon}{2}$ for all $n_{k} > N$. Since $a_{n}$ is Cauchy, there's also an $N$ large enough that $d(a_{n}, a_{m}) < \frac{\epsilon}{2}$ for $m,n > N$. Pick $N$ large enough such that both of these properties hold at the same time for $n_{k} > n > N$. By the triangle inequality, $d(a_{n}, c) \leq d(a_{n}, a_{n_{k}}) + d(a_{n_{k}}, c) < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$.

\fi


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item The Bolzano-Weirstrass theorem states that every bounded sequence of real numbers has a convergent subsequence. Use this property to show that the metric space $(X, d )$, where $X$ is a compact subset of reals, is complete.

\ifsln

\noindent
\textit{Solution:}\\
To show completeness we need to show that every Cauchy sequence converges to a point in the set. Let $\{x_{n}\}$ be a Cauchy sequence in $X$. Since $X$ is a compact subset of the reals, it is closed and bounded. Since $X$ is bounded, by the Bolzano-Weirstrass theorem, the sequence must have a convergent subsequence. From the solution above, if a Cauchy sequence has a convergent subsequence, then the whole sequence also converges to that point. Since $X$ is closed, the subsequence converges to a point in $X$. Therefore every Cauchy sequence converges to a point in $X$, and the space is complete.
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item  Solve the following systems of linear equations.

\begin{center}
\begin{tabular}{c c c}
	\begin{minipage}{0.3\textwidth}
	a)
	\begin{align*}
	x + 2y + z -  w = 1\\
	3x + 6y - z - 3w = 2
	\end{align*}	\\
	\end{minipage}
&	
	\begin{minipage}{0.3\textwidth}
	b)
	\begin{align*}
	x + 2z = 0\\
	x + y + 2z = 2\\
	2x + y + 4z = 3\\
	5x + 10z = 0
	\end{align*}
	\end{minipage}
&
	\begin{minipage}{0.3\textwidth}
	c)
	\begin{align*}
	x + y  = 15\\
	2y = 20\\
	x + 3y = 35\\
	2x + 4y = 50
	\end{align*}
	\end{minipage}
\end{tabular}
\end{center}


\ifsln
\textit{Solution:}\\
a)\\
$\left(
\begin{array}{cccc|c}
1 & 2 & 1  & -1 & 1\\
3 & 6 & -1 & -3 & 2 
\end{array}
\right)
\overset{\text{rref}}{\to}
\left(
\begin{array}{cccc|c}
1 & 2 & 0  & -1 & \frac{3}{4}\\
0 & 0 & 1 & 0 & \frac{1}{4} 
\end{array}
\right)
$\\

Columns 1 and 3 are the basic variables. Columns 2 and 4 the free variables. We have $x_{1} = \frac{3}{4} - 2x_{2} + x_{4}$. $x_{2} = x_{2}$. $x_{3} = \frac{1}{4}$. $x_{4} = x_{4}$. Or\\

$\begin{pmatrix}
x_{1}\\
x_{2}\\
x_{3}\\
x_{4}
\end{pmatrix}
= 
\begin{pmatrix}
\frac{3}{4}\\
0\\
\frac{1}{4}\\
0
\end{pmatrix}
+ 
\begin{pmatrix}
-2\\
1\\
0\\
0
\end{pmatrix}
x_{2}
+ 
\begin{pmatrix}
1\\
0\\
0\\
1
\end{pmatrix}
x_{4}
$

\medskip
b)\\

$\left(
\begin{array}{ccc|c}
1 & 0 & 2  & 0\\
1 & 2 & 2 & 2\\
2 & 1 & 4 & 3\\
5 & 0 & 10 & 0
\end{array}
\right)
\overset{\text{rref}}{\to}
\left(
\begin{array}{ccc|c}
1 & 0 & 2  & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 0 & 1\\
0 & 0 & 0 & 0
\end{array}
\right)
$\\

Last column is a basic column. No solutions.


\medskip
c)\\

$\left(
\begin{array}{cc|c}
1 & 1 & 15 \\
0 & 2 & 20 \\
1 & 3 & 35 \\
2 & 4 & 50
\end{array}
\right)
\overset{\text{rref}}{\to}
\left(
\begin{array}{cc|c}
1 & 0 & 5 \\
0 & 1 & 10 \\
0 & 0 & 0 \\
0 & 0 & 0 
\end{array}
\right)
$\\

Unique solution. $x_{1} = 5$, $x_{2} = 10$.

\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Do the vectors $v_{1} = \begin{bmatrix} 1 \\ 2 \\1 \end{bmatrix}$, $v_{2} = \begin{bmatrix} 2 \\ 1 \\2 \end{bmatrix}$, $v_{3} = \begin{bmatrix} 3 \\ 3 \\2 \end{bmatrix}$, form  a basis for $\R^{3}$?

\ifsln
\textit{Solution:}\\
Since $\R^{3}$ is 3 dimensional, a basis must have exactly 3 vectors, which we have. To determine whether they are linearly independent, we can use the determinant:\\

\begin{align*}
\det \begin{pmatrix}1 & 2& 3 \\ 2 & 1& 3 \\ 1&2&2 \end{pmatrix} &
= 1\cdot (-1)^{1 + 1} \cdot \left| \begin{array}{cc} 1 & 3\\ 2 & 2 \end{array} \right | + 2\cdot (-1)^{1 + 2} \cdot \left| \begin{array}{cc} 2 & 3\\ 1 & 2 \end{array}\right| + 3\cdot (-1)^{1 + 2} \cdot \left| \begin{array}{cc} 2 & 1\\ 1 & 2 \end{array}\right|\\
&= 1\cdot (2-6) -2\cdot (4-3) + 3\cdot (4-1)\\
&= -4 -2 + 9\\
& = 3
\end{align*}

Determinant is non-zero, so vectors are linearly independent.
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Consider the map $A = \begin{pmatrix}1 & 2 \\ 2 & 4\end{pmatrix}$. 
\begin{enumerate}[a)]
\item Find a basis for the column space.
\item Find a basis for the nullspace. 
\item Show that the column space and null space are orthogonal.
\end{enumerate}

\ifsln
\textit{Solution:}\\
a) $\begin{pmatrix}1 & 2 \\ 2 & 4\end{pmatrix} \overset{\text{rref}}{\to} \begin{pmatrix}1 & 2 \\ 0 & 0\end{pmatrix}$. The basic column form a basis for the column space, $col(A) = \text{span}\{\begin{bmatrix}1 \\ 2\end{bmatrix}\}$.\\

b) The nullspace is the set of vectors, $x$ that solve $Ax = 0$. Set up the augmented matrix and put in rref. 

$\left(
\begin{array}{cc|c}
1 & 2 & 0 \\
2 & 4 & 0 \\
\end{array}
\right)
\overset{\text{rref}}{\to}
\left(
\begin{array}{cc|c}
1 & 2 & 0 \\
0 & 0 & 0 \\
\end{array}
\right)
$

Which gives solutions $\begin{bmatrix}x_{1} \\ x_{2}\end{bmatrix} = \begin{bmatrix}-2 \\ 1 \end{bmatrix}x_{2}$. So $\text{Null}(A) = \text{span}\{\begin{bmatrix}-2 \\ 1 \end{bmatrix}\}$.\\

c) Each element of $col(A)$ has the form $\alpha\begin{bmatrix}1 \\ 2\end{bmatrix}$. Each element of the nullspace has the form $\beta \begin{bmatrix}-2 \\ 1 \end{bmatrix}$. To show orthogonality, the inner product of these must be zero.\\

$\langle \alpha\begin{bmatrix}1 \\ 2\end{bmatrix}, \beta \begin{bmatrix}-2 \\ 1 \end{bmatrix} \rangle = \alpha \beta (1\cdot -2 + 2 \cdot 1) = 0$.

\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Let $Ax=b$ be an $m\times n$ system of equations and let $\mathcal{S} = \{x \in \R^{n} \ | \ Ax = b\}$ be the solution set. Show that if $\mathcal{S}$ is non-empty, such that there is at least one particular solution, $x^{*}$, then $\mathcal{S}$ is the affine subspace $\mathcal{S} = \{x^{*} + v \ | \ v \in \text{Null}(A)\}$.\smallskip

(Hint: Show that if some vector $x^{\prime} \in \{x \in \R^{n} \ | \ Ax = b\}$ then it must also be in $\{x^{*} + v \ | \ v \in \text{Null}(A)\}$, and vice versa)\\

\ifsln
\textit{Solution:}\\
Let $x^{\prime} \in \{x \in \R^{n} \ | \ Ax = b\}$. Consider the vector $v = x^{\prime} - x^{*}$. $Av = A(x^{\prime} - x^{*}) = Ax^{\prime} - Ax^{*} = b - b = 0$. Therefore $v \in \text{Null}(A)$. So $x^{\prime}= x^{*} + v$, $v \in \text{Null}(A)$, and $x^{\prime} \in \{x^{*} + v \ | \ v \in \text{Null}(A)\}$.\\

Let $x^{\prime} \in \{x^{*} + v \ | \ v \in \text{Null}(A)\}$. Then $x^{\prime} = x^{*} + v$, for some $v \in \text{Null}(A)$. $Ax^{\prime} = A(x^{*} + v) = Ax^{*} + Av = b + 0 = b$. Therefore $x^{\prime} \in \{x \in \R^{n} \ | \ Ax = b\}$. \halmos
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\item Let $X$ be an $n \times p$ matrix with full column rank. Show that $X^{\prime}X$ is invertible.\smallskip

(Hint: Show that the nullspace of $X^{\prime}X$ only contains $0$) \\

\ifsln
\textit{Solution:}\\
Suppose there is a vector $v$ in the nullspace of $X^{\prime}X$, such that $X^{\prime}Xv = 0$. It must be that $v^{\prime}X^{\prime}Xv = 0$, since $v^{\prime}(X^{\prime}Xv) = v^{\prime}0 = 0$. But $v^{\prime}X^{\prime}Xv = (Xv)^{\prime}(Xv) = \langle Xv, Xv \rangle = ||Xv||^{2} = 0$.\\

$||Xv||^{2} = 0 \implies v = 0$, since $X$ is full column rank and so $\text{Null(X)}= \{0\}$. Therefore the only $v\in \text{Null}(X^{\prime}X)$ is $v=0$. Therefore $X^{\prime}X$ is full column rank. Since $X^{\prime}X$ is square, it must be invertible.


\fi


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{enumerate}
\end{document}
